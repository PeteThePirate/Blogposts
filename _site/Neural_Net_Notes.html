<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Neural Network Notes</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">My Website</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="Neural_Net_Notes.html">1. Feed-forward Neural Nets</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Neural Network Notes</h1>

</div>


<p>The purpose of this notebook is for me to document a whole bunch of little tips and tricks for myself that I may want to refer to later when building Feed Forward Neural Nets. It’s largely based on things I’ve picked up from Andrew Ng’s Deep Learning Specialization on Coursera, but over time I’ll hopefully be updating it with a things I’ve learnt from other sources, and learnings from mistakes I make along the way.</p>
<p>Because I’m writing this primarily for quick reference in future, this notebook tends to have a much drier tone than I would like. Sorry about that…</p>
<div id="activation-functions" class="section level1">
<h1>Activation Functions</h1>
<p>I’m not going to describe each function here since that’s really easy to look up. Rather I’m just going to make some notes about usage.</p>
<ul>
<li><p>Tanh is a superior choice to sigmoid function for hidden layers since it is exactly equal to the sigmoid function but shifted to be centered at zero.</p></li>
<li><p>Sigmoid function is useful as an output layer since it ranges between 0 and 1 (it’s basically logistic regression)</p></li>
<li><p><strong>ReLU should be my default activation function for hidden layers</strong>.</p></li>
<li><p>Softmax function is used as a final layer if we are using multiclass classification. It standardises the outputs to be interpretable as probabilities by ensuring they sum to 1.</p></li>
</ul>
</div>
<div id="traindevtest-set-selection" class="section level1">
<h1>Train/Dev/Test set selection</h1>
<p>For smaller datasets, 70/30/0 or 60/20/20 splits were common</p>
<p>But in practice, the Dev set only needs to be big enough to choose between multiple algorithms, and the test set only needs to be big enough to get a good estimate of the performance of the model on out-of-training data. This need scales with <em>n</em> rather than by <em>p</em>, so for a datasets of say 1,000,000 rows, it may be reasonable to take 10,000 rows each for dev and test and using the remainder for training.</p>
<p>Don’t rob from your training data unnecessarily.</p>
</div>
<div id="dealing-with-biasvariance-or-overfittingunderfitting" class="section level1">
<h1>Dealing with Bias/Variance or overfitting/underfitting</h1>
<p>Bias/Variance is an alternative view of “underfitting/overfitting” on your training set and we diagnose it by looking at the performance of the model on the training set versus the performance of the model on the dev set.</p>
<p>With Neural Nets, there is less of a tradeoff in the minimising bias and minimising variance. This is because we have tools that can isolate improvement in one metric while having little effect on the other. For example, if we have high bias (regardless of the variance), we could fit a bigger network (more layers or neurons in a layers) or train the neural net for longer. Once we are satisfied with the bias, we can deal with variance by either getting more data, or introducing more regularisation. With regards to regularisation, it basically means training a bigger neural net never hurts, it just takes longer.</p>
<p>So the tradeoff is no longer really <em>bias vs variance</em>, but rather <em>bias vs time to train</em>.</p>
</div>
<div id="regularisation" class="section level1">
<h1>Regularisation</h1>
<div id="l2-regularisation-weight-decay" class="section level2">
<h2>L2-regularisation (weight-decay)</h2>
<p>As expected from other regularisations, for example in lasso regression, regularisation in Neural Networks works by adding a penalisation term onto your cost function.</p>
<p>If we are to regularise the L2-norm (which would usually be the case), we can express the cost function to be minimised as <span class="math inline">\(J(w,b) = \frac{1}{m} \sum_{\forall m} \mathcal{L}(\hat y^{(i)},y^{(i)}) + \frac{\lambda}{2m}||w||^2_2\)</span>.</p>
<p>Andrew Ng recommends not bothering to regularise the bias term as well simply because the dimensionality of <span class="math inline">\(w \in \mathcal{R}^{n_x}\)</span> makes it much more important than <span class="math inline">\(b \in \mathcal{R}\)</span>. But the recommendation seems to be ‘its not worth the effort of coding it up’ rather than ‘there is some advantage to leaving it out’. The recommendation is made in the video <a href="https://www.coursera.org/learn/deep-neural-network/lecture/Srsrc/regularisation">Improving Deep Neural Networks: Hyperparameter tuning, Regularisation and Optimization/Week 1/Regularisation</a>.</p>
<p>For terminology reference, note that <span class="math inline">\(||w||^2_2 = \sum_{\forall{l}}{||w^{[l]}||^2}\)</span> where <span class="math inline">\(||w^{[l]}||^2\)</span> is the square of the <em>Frobenius</em> norm.</p>
<p>The term <em>weight decay</em> is because in backpropogation, the weight update step becomes <span class="math inline">\(w_{new}^{[l]} = \left( 1- \frac{\alpha\lambda}{m} \right) w_{old}^{[l]} - \alpha [\text{normal backprop value}]\)</span>.</p>
<p><strong>Why does L2-regularisation work?</strong></p>
<p>Ng gives intuition about setting Neurons to zero so fewer Neurons are used. I don’t believe this is correct. Rather, because of how L2 works, its more efficient for the Network to have many small activations than a few large activations. This should make the model need signal from a variety of sources to have large values, rather than just 1 neural path lighting up.</p>
<p>There is also intuition that keeping weights small, you also keep the inputs to the activation small, and so over a small range, the <em>tanh</em> and <em>sigmoid</em> functions are more approximately linear.</p>
<p><strong>L1 Regularisation</strong></p>
<p>Using L1-regularisation can also be done, with the effect that it will make your neural network more sparse by setting lots of the weights to zero. However in the same video as linked above, the comment is made that the compression gains aren’t great, so there should be some other motivating reason to use L1 over L2.</p>
</div>
<div id="dropout-regularisation" class="section level2">
<h2>Dropout Regularisation</h2>
<p><strong>What is it?</strong></p>
<p>Works by randomly selecting some Neurons, and setting their activations to zero. Different Neurons are selected in each training epoch. <em>Inverted Dropout</em> is the most common method of implementing dropout. Inverted Dropout reweights the incoming activations for each neuron in a layer by the expected number of live-neurons in the previous layer. This makes sure the overall magnitude of the activations of each layer remains constant through training and implementation. For example, if 80% of neurons in layer 1 are kept, you would take divide each activation in layer 1 by 0.8 when calculating the input to the activations in layer 2.</p>
<p><strong>Why does Dropout work?</strong></p>
<p>At Jupytercon 2017, it was pointed out that a Neural Network with connections missing is kind of like a Random Forest, but with some connections between some of the trees. So maybe it’s mimicing ensemble learning with a few networks in some sense, although with some violation of the usual independence assumption of bagging. During training it is also as if each of these networks being trained is smaller, so it mimics having less complicated networks.</p>
<p>Each neuron in the network can also not rely too much on any 1 neuron in the previous layer (since it might disappear), so it should learn signal from each source instead. This is a similar effect to L2-regularisation.</p>
<p><strong>Notes on Dropout</strong></p>
<ul>
<li>Usually we don’t apply dropout to the first layer of the network (ie, the actual features from the training data).</li>
<li>Dropout will add jitter to the Cost-graph, so it will not be monotonically decreasing.</li>
</ul>
</div>
<div id="other-regularisation-methods" class="section level2">
<h2>Other Regularisation methods</h2>
<ul>
<li>Get more training data by augmenting training set (flipping, rotating, random cropping etc)</li>
<li>Early stopping - stop updating the Neural Network when the dev-set error starts increasing. This does have a downside though in that you’re entering into the bias/variance tradeoff. Other methods are <em>Orthogonal</em> in that they can fix one aspect of your model while having little effect on others.</li>
</ul>
</div>
</div>
<div id="setting-up-your-optimization-problem" class="section level1">
<h1>Setting up your optimization problem</h1>
<div id="normalize-your-inputs" class="section level2">
<h2>Normalize your inputs</h2>
<p>As usual, its best to normalise data to be zero-mean and unit variance. Note - calculate the training set means and variances for each feature, and use these means and variances on the test set and in production as well. It will make your network train faster.</p>
</div>
<div id="vanishingexploding-gradients" class="section level2">
<h2>Vanishing/Exploding Gradients</h2>
<p>Imagine a very deep network, such as in the image provided.</p>
<div class="figure">
<img src="Images/Vanishing_gradients_example.png" alt="example NN for exploding/vanishing gradients from Andrew Ng’s Coursera course" />
<p class="caption">example NN for exploding/vanishing gradients from Andrew Ng’s Coursera course</p>
</div>
<p>For simplicity, if we assume a linear activation, and no bias terms, then <span class="math inline">\(\hat y = w^{[L]}w^{[L-1]}\dots w^{[3]}w^{[2]}w^{[1]}X\)</span>. If the average value of each of the weight matrices is less than 1, we can see that the value of y will tend towards 0. Similarly if the average magnitude is greater than 1, the value of y will explode. Furthermore, the activations will all also explode or vanish, since <span class="math inline">\(a^{[l]} = w^{[l]}w^{[l-1]}\dots w^{[1]}X\)</span>. By ‘average value of each of the weight matrices’, I think this might just mean the determinants of each of these matrices, but I’d need to check that.</p>
<p>The Vanishing Gradient problem can be solved by using a better choice of Weight Initialisation for the network (See Xavier weight initialisation section).</p>
<p>##Weight Initialization</p>
<p>To solve for the Vanishing/Exploding Gradient problem, we can control the magnitudes of the weight-matrices when we initialise them to have roughly unit-magnitude. We do this by scaling the variance of each individual element within the matrix so the the sum of the variances is 1.</p>
<p>So if a neuron has <span class="math inline">\(n\)</span> inputs, we can initialise each weight as a random-normal variable with variance proportional to <span class="math inline">\(1/n\)</span>.</p>
<ul>
<li>For ReLU, it works best to have variance <span class="math inline">\(2/n\)</span>. I guess because only half the x-axis is actually used in ReLU?</li>
<li>tanh, it works best to have variance <span class="math inline">\(1/n\)</span> (This is Xavier initialisation)</li>
</ul>
<p>This initialisation magnitude can be tuned, but it’s super low priority.</p>
<p>#Optimisation Algorithms</p>
<p>The key takeouts here are:</p>
<ul>
<li>Always use mini-batch learning (unless the input data is super small).</li>
<li>Always use Adam optimisation. Adam includes momentum as well as RMSProp, so it seems to be the good default choice.</li>
</ul>
<p>##Mini-batch gradient descent</p>
<p>Basically, it’s a waste of time to use all the millions of training points to adjust the weights by a super small learning_rate. Rather use really small subsets of the data, to get a rough estimate of the gradient, then perform backpropagation. You may jitter around a bit, but you’ll generally be going in the right direction. And using Momentum or Adam we can fix this jitter anyway.</p>
<p>The steps for mini-batch are:</p>
<ul>
<li>Shuffle your data</li>
<li>Segment your data into small subsets (called a mini-batch). Andrew Ng suggests much smaller than I expected.</li>
<li>For each mini-batch, perform an iteration of forward and backward propogation</li>
<li>go to the next mini-batch</li>
</ul>
<p><strong>Some notes on mini-batch</strong></p>
<ul>
<li>Going through your entire dataset once is referred to as an <em>‘epoch’</em>.</li>
<li>Your cost function will no longer be strictly decreasing as you iterate, since you may randomly get harder-to-predict mini-batches. <em>Typically mini-batches are of size 64,128,256,512. </em>If your dataset is small, don’t bother (say, fewer than 2000 samples). *Make sure your mini-batch fits its CPU/GPU memory, otherwise you’ll have a lot of loss in learning time.</li>
</ul>
<p>##Exponentially Weighted Averages</p>
<p>##Gradient Descent with Momentum</p>
<p>##RMSProp</p>
<p>To be honest I didn’t really get RMSProp</p>
<p>##Adam Optimisation</p>
<p>Basically Adam is RMSProp + Momentum. Use this as your default optimiser.</p>
<p>##Learning Rate Decay</p>
<p>##Problem of Local Optima</p>
<p>#Hyperparameter Tuning</p>
<p>##Order of hyperparameter importance for tuning</p>
<p>This is based on Andrew Ng’s recommendations</p>
<ol style="list-style-type: decimal">
<li><p>The learning rate</p></li>
<li><ol style="list-style-type: lower-alpha">
<li>Momentum (default ~ 0.9)</li>
<li>The number of hidden units</li>
<li>Mini-batch size</li>
</ol></li>
<li><ol style="list-style-type: lower-alpha">
<li>The number of layers</li>
<li>Learning rate decay</li>
</ol></li>
<li><p>Basically only ever use default parameters for Adam Algorithm</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(\beta_1 = 0.9\)</span></li>
<li><span class="math inline">\(\beta_2 = 0.99\)</span></li>
<li><span class="math inline">\(\epsilon = 10^{-8}\)</span></li>
</ol></li>
</ol>
<p>##Approaches to hyperparameter tuning</p>
<p>Sometimes, data-scientists will babysit a single model, manually tuning and refining it so the the model is constantly improving over time.</p>
<p>Other times, a data-scientist will train many models in parallel and see which model performs the best after a decent amount of time.</p>
<p>Andrew Ng refers to this as the Panda approach vs the Caviar approach - where pandas have a single child that they care for, whereas fish lay many eggs, and wait and see which ones survive.</p>
<p>To choose between these approaches, you must consider how much computational resource you have. If you have plenty, use the Caviar approach. If you are more constrained, use the Panda approach.</p>
</div>
<div id="dont-sample-in-a-grid.-rather-sample-at-random" class="section level2">
<h2>Don’t sample in a grid. Rather sample at random</h2>
<div class="figure">
<img src="Images/random_hyperparameters.png" alt="from Andrew Ng’s Coursera course" />
<p class="caption">from Andrew Ng’s Coursera course</p>
</div>
<p>Imagine you have 2 hyperparameters to tune, but hyperparameter 2 actually has no effect on the performance of your model. If you sample 25 points in a <span class="math inline">\(5 \times 5\)</span> grid, you’ve only tested 5 distinct values for hyperparameter 1. But if you’d randomly selected points in the 2-dimensional space, even if hyperparameter 2 is useless, you’ve still tested 25 distinct values for hyperparameter 1.</p>
<p>##Course-to-fine scheme</p>
<p>Instead of sampling uniformly over the entire space of candidate hyperparameter values, you can first select a few random values over a large space, then observe which regions seem to have the best performance. A second stage of searching can then be performed only in this region where we have seen the model performs well.</p>
<p>##Sample on the appropriate scale (log-sampling for some parameters)</p>
<p>Say you’re tuning the learning rate, and you suspect the best value lies in the region <span class="math inline">\((0.0001, 1)\)</span>. If you sample uniformly, you will be using roughly 99% of your samples to test values between 0.001 and 1, and only 1% of your sample to test between 0.0001 and 0.001. It makes more sense to randomly select values on the log-scale using the uniform distribution, and then to convert those values back to the linear scale.</p>
<p>So for the example given above one would</p>
<ol style="list-style-type: decimal">
<li><p>Generate r = -4U where U ~ Uniform(0,1). Then <span class="math inline">\(r \in [-4,0]\)</span></p></li>
<li><p>Set <span class="math inline">\(\alpha = 10^r\)</span> so that <span class="math inline">\(\alpha \in [10^{-4}, 10^0]\)</span> or <span class="math inline">\(\alpha \in [0.0001,1]\)</span></p></li>
</ol>
<p>Similarly, say we want to use exponentially weighted averages, and we want to test values for <span class="math inline">\(\beta \in [0.9, 0.999]\)</span>. The process would be</p>
<ol style="list-style-type: decimal">
<li>Generate r = -2U - 1. Then <span class="math inline">\(r \in [-3,-1]\)</span></li>
<li>Set <span class="math inline">\(1-\beta = 10^r\)</span>. Then <span class="math inline">\(\beta = 1-10^r \in [0.9, 0.999]\)</span> as required.</li>
</ol>
<p>##Batch-Normalization</p>
<p>This makes your Neural Network much more robust to hyperparameter selection and thus speeds up training.</p>
<p>Instead of just normalising the inputs to the Neural Network, we normalise the inputs every layer by normalizing either the activations, or the linear-component of the previous layer. It is debatable which should be normalised, but the most common is to normalise the linear component.</p>
<p><strong>To perform batch normalisation</strong></p>
<ul>
<li>For each <span class="math inline">\(Z^{(i)}\)</span> in layer l, set <span class="math inline">\(Z_{norm}^{(i)} = \frac{ Z^{(i)} - \mu}{\sqrt{\sigma^2 + \epsilon}}\)</span> using the (mini-batch) sample mean and variance.</li>
<li>Then set <span class="math inline">\(\tilde{z} = \gamma Z_{norm}^{(i)} + \beta\)</span> where <span class="math inline">\(\gamma\)</span> and <span class="math inline">\(\beta\)</span> are learnable parameters of the model.</li>
</ul>
<p>Basically, we are setting the location and distribution of each neuron to be learnable parameters.</p>
<p><strong>Using batch-norm replaces the bias parameter in each node</strong> This is because <span class="math inline">\(\beta\)</span> and the bias parameter would both act as scaling-constants. It’s maybe not clear in the example above, but <span class="math inline">\(\gamma\)</span> and <span class="math inline">\(\beta\)</span> would both be vectors with dimensions <span class="math inline">\((n^{[l]}, 1)\)</span> (ie, every neuron gets it’s own learned value).</p>
<p><strong>Why does batch-norm work?</strong></p>
<p>There are multiple intuitions here:</p>
<ol style="list-style-type: decimal">
<li><p>In the same way that normalising the inputs to the first layer of the network speeds up learning, normalising later layers should do the same.</p></li>
<li><p>During training, a deeper layer is learning the best weights based on some values of activations of the previous layer. But these previous layer values are also getting updated, so there is ‘covariate shift’. By using <span class="math inline">\(z_{norm}\)</span>, then applying our own scaling, we ‘undo’ any shifts in the activations, and the neuron can focus on learning from the patterns of its inputs instead.</p></li>
<li><p>Has a slight regularization effect. Since when training with mini-batches, we normalise with a different sample mean and variance each time, we are introducing some noise into the activations of the hidden layer. This is sort of the same as dropout though which adds news to activations by randomly removing nodes. Thus adding regularization forces the model to not depend too much on any one feature. This is kind of flimsy though, and Batch-norm shouldn’t be used for the intention of regularization.</p></li>
</ol>
<p><strong>At prediction time</strong></p>
<p>At prediction on a single sample, you won’t have a sample mean and variance to use to calculate <span class="math inline">\(z_{norm}\)</span>. To deal with this, at training time, we keep track of a <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> estimate using exponentially weighted moving averages during training. These values are then used during prediction. Most frameworks should take this into account for you so I wouldn’t worry about it.</p>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
